@article{kearnes2016molecular,
  title={Molecular graph convolutions: moving beyond fingerprints},
  author={Kearnes, Steven and McCloskey, Kevin and Berndl, Marc and Pande, Vijay and Riley, Patrick},
  journal={Journal of Computer-Aided Molecular Design},
  volume={30},
  number={8},
  pages={595--608},
  year={2016}
}

@inproceedings{wu2019session,
  title={{Session-based Recommendation with Graph Neural Networks}},
  author={Wu, Shu and Tang, Yuyuan and Zhu, Yanqiao and Wang, Liang and Xie, Xing and Tan, Tieniu},
  booktitle={Proceedings of the 33rd AAAI Conference on Artificial Intelligence},
  pages={346--353},
  year={2019}
}

@ARTICLE{9720918,

  author={Li, Yan and Li, Nianfeng},

  journal={IEEE Access}, 

  title={Sentiment Analysis of Weibo Comments Based on Graph Neural Network}, 

  year={2022},

  volume={10},

  number={},

  pages={23497-23510},

  doi={10.1109/ACCESS.2022.3154107}}


@article{LIAO2021107096,
title = {Multi-level graph neural network for text sentiment analysis},
journal = {Computers & Electrical Engineering},
volume = {92},
pages = {107096},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107096},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621001051},
author = {Wenxiong Liao and Bi Zeng and Jianqi Liu and Pengfei Wei and Xiaochun Cheng and Weiwen Zhang},
keywords = {text sentiment analysis, graph neural network, attention mechanism, deep learning},
abstract = {Text sentiment analysis is a fundamental task in the field of natural language processing (NLP). Recently, graph neural networks (GNNs) have achieved excellent performance in various NLP tasks. However, a GNN only considers the adjacent words when updating the node representations of the graph, and thus the model can only focus on the local features while ignoring global features. In this paper, we propose a novel multi-level graph neural network (MLGNN) for text sentiment analysis. To consider both local features and global features, we apply node connection windows with different sizes at different levels. Particularly, we integrate a scaled dot-product attention mechanism as a message passing mechanism into our method for fusing the features of each word node in the graph. The experimental results demonstrated that the proposed model outperformed other models in text sentiment analysis tasks.}
}