# Assignment 
## Research

My research topic, Autonomous driving, has been very popular lately, both in corporations and academia. A core challenge and the focus of my study is determining the future paths of every road user on the road, from cars and pedestrians to cyclists and motorcyclists. This is crucial for autonomous driving's situational understanding. The challenge lies in using HD maps and past movement paths to predict where these road participants might go next. Ensuring these predictions are accurate is very important for the safety of self-driving cars, minimizing potential collisions.

With advancements in technology, deep learning, especially in recent times, has become a powerful tool in this field, which makes the prediction outperforms a lot compared to the traditional methods in many aspects. It makes the models easy for adaptability, scalability, and ability to discern intricate data trends to output precise future path predictions. Training for these models often involves large datasets like Argoverse [1], Waymo [2], Nuscenes [3], Interaction [4]...). These datasets consist millions of recorded scenarios including the data of past movement trajectories paired with high-resolution map topology in different cities. Supervised learning strategies are used with different network model architectures including convolutional neural networks, recurrent neural networks, graph neural networks [5], and Transformers [6], etc. 

However, in order to make the prediction as both comprehensive and logical, a solid prediction isn't just about accuracy; it needs to consider the variety and coordinated thinking. The former means that road users can have variable future paths as it will be in nature. The output should indicate that multiple outcomes are always a possibility. Therefore, while making predictions, it's critical to both pinpoint the most probable pathway but also alternative trajectories. The latter emphasizes the simultaneous prediction of every road user's path since the mutual interactions and influence among road users can not be ignore, however, it is very hard to capture. To address these problems, it's essential to develop sophisticated deep learning models that can process the unpredictable nature of future paths and understand complex and variable scenarios with road user interactions in real-time.

## 2 Points from Robert's lectures
Here I will discuss 2 points from Robert's lectures. 

First is about the trade-off between the model accuracy and explainability in the machine learning models. As the recent large language models achieve big success in generation and understanding of text and images, more and more researchers are convinced with the great magic of big models fed with big data. However, the issues of explainability arise up. It is also a big concern in my research field. The core of autonomous driving is around ensuring safety. A motion prediction model must be highly accurate to anticipate the movements of all road users and make real-time decisions to prevent accidents. While a highly complex model might achieve better accuracy, if it lacks explainability, it can become challenging to trust the model's decisions. It becomes almost impossible to diagnose its failures directly. Researchers and engineers usually add some rules to fine-tune its behavior or feed more corner cases data to the network. For instance, in an accident scenario, it is crucial to understand why the model made a specific decision. From a research perspective, traditional methods, although it is less accurate, the explainability is not an issue since models are defined based on physical kinematic models, rule-based heuristic way.  Explainable models offer the advantage of being easier to debugging and refinement. If researchers and engineers can understand the reasoning behind predictions, they can more effectively address shortcomings or anomalies in the model's behavior. However, for the machine learning, especially for the deep learning, there are not proper way to solve it yet. 

Second is about the testing. It is important to provide a framework to evaluate the accuracy, safety, and robustness of motion prediction models. Currently, the most common way to evaluate the performance in the papers is to use common open benchmarks. With identical datasets, researchers can compare the performance of various motion prediction algorithms under similar conditions, to identify the most promising approaches. There are multiple benchmarks in the field, for example, benchmarks provided by Argoverse and Waymo. However, in reality, even for the high-ranked algorithms, they are not entirely trustworthy. This is due to the limitation of these dataset. The process of selecting or generating test scenarios is non-trivial. It's crucial to test models under scenarios that represent everyday driving situations. These scenarios can be sourced from real-world data captured by sensors on vehicles, ensuring the models are exposed to typical driving conditions. Moreover, it requires to include almost all corner cases, which is tough.

## 2 Points from guests’ lectures
Here I will discuss 2 points from guests’ lectures.

First is about the supervised and unsupervised learning. As we all know, supervised learning needs labeled ground truth, while unsupervised learning tries to learn from the data itself. Unsupervised learning in general makes the models scalable and generalized. In the motion prediction, we can use random masking strategy which intentionally hide or “masked” certain parts of the data, for example, to learn the interpretation of the context. By trying to fill in or predict these missing sections, the model can gain a deeper understanding of context and interactions between various road users.

Second is about AutoML, which is a tool that automates the process of testing network models. Some known tools include like Google's Cloud AutoML, H2O's Driverless AI, and Microsoft's Azure Machine Learning. I don’t have much experience on them. However, I think they have potential to greatly prosper the speed of developing in my field. It will faster model creation. Instead of spending weeks tweaking a model, AutoML can do it in less time in a full automation manner. It also faster iterations and the ability to test various models in a short time. This not only expedites the research process but also in identifying the more effective algorithms and features for accurate motion.

## Security and Privacy
For the public, it's essential for users to trust autonomous vehicles. When the decision-making process of autonomous vehicles is transparent and understandable, passengers and the public at large can develop greater trust in the technology. On the other hand, a car making decisions based on a "black box" model, regardless of its accuracy, might face resistance from potential users. Unfortunately, this is what happens now. The majority of people don’t trust autonomous driving due to many factors and reasons. Besides the lack of explainability and the immature testing strategy mentioned above, ethical dilemmas faced by autonomous vehicles in unavoidable crash situations, for example, are also a matter of public concern. Who gets to decide the programming of such life-and-death decisions, and on what basis? Moreover, there are concerns about the data storage security and the privacy. Autonomous vehicles rely on a set of sensors like lidar, cameras, which constantly gather data to understand and navigate their environment. This data can be very sensitive as it captures personal information like human faces, leading to concerns about surveillance and misuse or abuse of personal data. 

## Regulations and Compliance
Regulations and compliance play an important role in shaping the trajectory of research. Authorities want self-driving cars to explain their decisions. A model that's accurate but hard to understand might face approval challenges. This encourages researchers to either make these models more interpretable or explore alternative methods that might be more explainable, even if slightly less accurate. Safety and reliability standards are needed. These standards aren't just about the accuracy of predictions; they also emphasize the importance of consistency and how the model reacts under various circumstances. For instance, a motion prediction model might be highly accurate in a simple environment, but how does it behave in unpredictable complex scenarios like in roundabouts and intersections? In a word, while regulations and compliance might seem like hurdles, they actually help to gain the public’s trust and make the field more sustainable. They push researchers to think beyond just accuracy, considering safety and reliability.

### Reference
[1] Chang, Ming-Fang, et al. "Argoverse: 3d tracking and forecasting with rich maps." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019.
[2] Sun, Pei, et al. "Scalability in perception for autonomous driving: Waymo open dataset." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.
[3] Caesar, Holger, et al. "nuscenes: A multimodal dataset for autonomous driving." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.
[4] Zhan, Wei, et al. "Interaction dataset: An international, adversarial and cooperative motion dataset in interactive driving scenarios with semantic maps." arXiv preprint arXiv:1910.03088 (2019).
[5] Liang, Ming, et al. "Learning lane graph representations for motion forecasting." Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part II 16. Springer International Publishing, 2020.
[6] Zhou, Zikang, et al. "Hivt: Hierarchical vector transformer for multi-agent motion prediction." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.